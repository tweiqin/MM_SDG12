name: MM - Database Migration

on:
  workflow_dispatch:
    inputs:
      confirm:
        description: 'Type "yes" to confirm migration (SAFE: No Data Loss)'
        required: true
        default: 'no'

jobs:
  migrate:
    name: Run Django Migrate
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout Code
      uses: actions/checkout@v4

    - name: Configure AWS Credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: "ap-southeast-1"

    - name: Execute Migration via SSM
      shell: bash
      env:
        DB_HOST: ${{ secrets.DB_HOST }}
        DB_USER: ${{ secrets.DB_USERNAME }}
        DB_PASS: ${{ secrets.DB_PASSWORD }}
        DB_NAME: "makanmystery_db"
      run: |
        if [[ "${{ github.event.inputs.confirm }}" != "yes" ]]; then
          echo "Please confirm by typing 'yes' in the workflow input."
          exit 1
        fi

        echo ">>> Step 1: Locating Web ASG..."
        # Find ASG Name dynamically (ends with -web-asg)
        ASG_NAME=$(aws autoscaling describe-auto-scaling-groups --query "AutoScalingGroups[?contains(AutoScalingGroupName, '-web-asg')].AutoScalingGroupName" --output text | head -n 1)

        if [ -z "$ASG_NAME" ] || [ "$ASG_NAME" == "None" ]; then
           echo "Error: Could not find Web ASG."
           exit 1
        fi
        echo "   ASG: $ASG_NAME"

        echo ">>> Step 2: Finding Healthy Instance..."
        INSTANCE_ID=$(aws autoscaling describe-auto-scaling-groups --auto-scaling-group-names "$ASG_NAME" --query "AutoScalingGroups[0].Instances[?LifecycleState=='InService'].InstanceId | [0]" --output text)

        if [ "$INSTANCE_ID" == "None" ] || [ -z "$INSTANCE_ID" ]; then
           echo "Error: No instances found in ASG!"
           exit 1
        fi
        echo "   Target Instance: $INSTANCE_ID"

        echo ">>> Step 3: Sending Migration Command..."
        
        # We need to execute the migration inside the running container.
        # The SQL file is located at /var/www/html/mm_sdg12.sql inside the container.
        
        # Construct the command to run on the EC2 instance
        # 1. Find the container ID
        # 2. Exec into container and run mysql
        
        # NOTE: We are embedding secrets into the command string. This is sent to SSM.
        # Be careful with quoting.
        
        CMD_RAW="docker_id=\$(sudo docker ps -q --filter ancestor=tweiqin/makanmystery:latest | head -n 1) && \
        if [ -z \"\$docker_id\" ]; then echo 'Container tweiqin/makanmystery not found!'; exit 1; fi && \
        echo \"Found Container: \$docker_id\" && \
        sudo docker exec \$docker_id sh -c \"mysql -h $DB_HOST -u $DB_USER -p'$DB_PASS' $DB_NAME < /var/www/html/mm_sdg12.sql\""
        
        # Escape double quotes for JSON parameter passing to SSM
        CMD_ESCAPED=${CMD_RAW//\"/\\\"}
        PARAMS_JSON="{\"commands\":[\"$CMD_ESCAPED\"]}"

        COMMAND_ID=$(aws ssm send-command \
          --instance-ids "$INSTANCE_ID" \
          --document-name "AWS-RunShellScript" \
          --parameters "$PARAMS_JSON" \
          --query "Command.CommandId" \
          --output text)

        echo "   Command Sent! ID: $COMMAND_ID"
        
        # Wait for command execution
        aws ssm wait command-executed --command-id "$COMMAND_ID" --instance-id "$INSTANCE_ID" || true

        # Fetch output
        echo ">>> Output:"
        aws ssm get-command-invocation --command-id "$COMMAND_ID" --instance-id "$INSTANCE_ID" --query "StandardOutputContent" --output text
        
        # Fetch errors
        ERRORS=$(aws ssm get-command-invocation --command-id "$COMMAND_ID" --instance-id "$INSTANCE_ID" --query "StandardErrorContent" --output text)
        if [ ! -z "$ERRORS" ]; then
           echo ">>> Errors:"
           echo "$ERRORS"
           # We don't exit 1 here immediately because sometimes legitimate output is in stderr (warnings), 
           # but for migration usually silence is golden or specific errors.
           # If it fails, usually mysql returns non-zero exit code which SSM captures as status.
           # Let's check status.
           STATUS=$(aws ssm get-command-invocation --command-id "$COMMAND_ID" --instance-id "$INSTANCE_ID" --query "Status" --output text)
           if [ "$STATUS" == "Failed" ]; then
              echo "Migration Failed."
              exit 1
           fi
        fi
        echo ">>> Migration Complete!"
